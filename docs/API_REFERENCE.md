# PageIndex API å‚è€ƒ

## ğŸ“‹ æ ¸å¿ƒæ¨¡å—

### 1. OCRç´¢å¼•ç”Ÿæˆ (`ocr_indexing.py`)

#### `generate_ocr_index(ocr_file_path, model_id, scenario="water_engineering")`

ç”ŸæˆOCRæ–‡æ¡£çš„æ™ºèƒ½ç´¢å¼•ã€‚

**å‚æ•°ï¼š**
- `ocr_file_path` (str): OCR JSONæ–‡ä»¶è·¯å¾„
- `model_id` (str): æ¨¡å‹ID
- `scenario` (str): åœºæ™¯åç§°ï¼Œé»˜è®¤"water_engineering"

**è¿”å›å€¼ï¼š**
```python
{
    "success": True,
    "output_file": "path/to/index.json",
    "indexing_stats": {
        "total_calls": 10,
        "successful_calls": 9,
        "failed_calls": 1,
        "total_time": 120.5,
        "total_tokens": 15000
    }
}
```

**ç¤ºä¾‹ï¼š**
```python
from ocr_indexing import generate_ocr_index

result = generate_ocr_index("ddh.pdf_content_list.json", "qwen3-32b")
print(f"ç´¢å¼•æ–‡ä»¶: {result['output_file']}")
```

#### `create_ocr_structure_with_llm(ocr_data, model_config, scenario="water_engineering")`

ä½¿ç”¨LLMåˆ†æOCRæ•°æ®å¹¶ç”Ÿæˆæ–‡æ¡£ç»“æ„ã€‚

**å‚æ•°ï¼š**
- `ocr_data` (list): OCRæ•°æ®åˆ—è¡¨
- `model_config` (ModelConfig): æ¨¡å‹é…ç½®å¯¹è±¡
- `scenario` (str): åœºæ™¯åç§°

**è¿”å›å€¼ï¼š**
```python
{
    "structure": [
        {
            "title": "èŠ‚ç‚¹æ ‡é¢˜",
            "start_page": 1,
            "end_page": 3,
            "summary": "èŠ‚ç‚¹æ‘˜è¦",
            "has_tables": True,
            "table_count": 2,
            "key_metrics": ["åº“å®¹", "è£…æœºå®¹é‡"],
            "content_type": "technical_specs",
            "granularity": "high"
        }
    ]
}
```

### 2. æ™ºèƒ½æœç´¢ (`intelligent_ocr_search.py`)

#### `search_with_llm(index_file_path, query, model_id, scenario="water_engineering")`

æ‰§è¡Œæ™ºèƒ½æœç´¢ã€‚

**å‚æ•°ï¼š**
- `index_file_path` (str): ç´¢å¼•æ–‡ä»¶è·¯å¾„
- `query` (str): æŸ¥è¯¢é—®é¢˜
- `model_id` (str): æ¨¡å‹ID
- `scenario` (str): åœºæ™¯åç§°

**è¿”å›å€¼ï¼š**
```python
{
    "success": True,
    "answer": "åŸºäºæ–‡æ¡£çš„è¯¦ç»†å›ç­”",
    "relevant_chapters": [
        {
            "chapter_id": "chapter_1",
            "relevance_score": 0.9,
            "reason": "åŒ…å«ç›¸å…³æ•°æ®"
        }
    ],
    "token_stats": {
        "total_calls": 3,
        "total_tokens": 5000,
        "input_tokens": 3000,
        "output_tokens": 2000
    },
    "call_details": [
        {
            "step": "æŸ¥è¯¢åˆ†æ",
            "elapsed_time": 2.1,
            "input_tokens": 1000,
            "output_tokens": 500
        }
    ]
}
```

**ç¤ºä¾‹ï¼š**
```python
from intelligent_ocr_search import search_with_llm

result = search_with_llm("index.json", "æ€»åº“å®¹æ˜¯å¤šå°‘", "qwen3-32b")
if result["success"]:
    print(f"ç­”æ¡ˆ: {result['answer']}")
```

#### `intelligent_search(index_data, ocr_data, query, model_config, scenario="water_engineering")`

æ ¸å¿ƒæœç´¢é€»è¾‘ã€‚

**å‚æ•°ï¼š**
- `index_data` (dict): ç´¢å¼•æ•°æ®
- `ocr_data` (list): OCRæ•°æ®
- `query` (str): æŸ¥è¯¢é—®é¢˜
- `model_config` (ModelConfig): æ¨¡å‹é…ç½®
- `scenario` (str): åœºæ™¯åç§°

**è¿”å›å€¼ï¼š** ä¸ `search_with_llm` ç›¸åŒ

### 3. æ¨¡å‹ç®¡ç† (`model_manager.py`)

#### `ModelManager`

æ¨¡å‹ç®¡ç†å™¨ç±»ã€‚

**åˆå§‹åŒ–ï¼š**
```python
from model_manager import ModelManager

# ä½¿ç”¨é»˜è®¤é…ç½®
manager = ModelManager()

# æˆ–æŒ‡å®šé…ç½®æ–‡ä»¶
manager = ModelManager("custom_config.yaml")
```

**ä¸»è¦æ–¹æ³•ï¼š**

##### `get_available_models()`

è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ã€‚

**è¿”å›å€¼ï¼š**
```python
[
    {
        "id": "qwen3-32b",
        "name": "Qwen3-32B",
        "enabled": True
    }
]
```

##### `call_model(prompt, model_id=None, max_retries=3)`

è°ƒç”¨æ¨¡å‹ã€‚

**å‚æ•°ï¼š**
- `prompt` (str): æç¤ºè¯
- `model_id` (str): æ¨¡å‹IDï¼Œé»˜è®¤ä½¿ç”¨é»˜è®¤æ¨¡å‹
- `max_retries` (int): æœ€å¤§é‡è¯•æ¬¡æ•°

**è¿”å›å€¼ï¼š**
```python
{
    "response": "æ¨¡å‹å“åº”",
    "usage": {
        "prompt_tokens": 1000,
        "completion_tokens": 500,
        "total_tokens": 1500
    }
}
```

##### `get_directory(dir_type)`

è·å–ç›®å½•è·¯å¾„ã€‚

**å‚æ•°ï¼š**
- `dir_type` (str): ç›®å½•ç±»å‹ ("ocr_files", "index_files", "temp_files")

**è¿”å›å€¼ï¼š** ç›®å½•è·¯å¾„å­—ç¬¦ä¸²

##### `get_indexing_config()`

è·å–ç´¢å¼•é…ç½®ã€‚

**è¿”å›å€¼ï¼š**
```python
{
    "toc_check_page_num": 10,
    "max_page_num_each_node": 3,
    "if_add_node_id": True,
    "if_add_node_summary": True,
    "if_add_doc_description": True,
    "if_add_node_text": True
}
```

### 4. æç¤ºè¯ç®¡ç† (`prompt_templates.py`)

#### `PromptManager`

æç¤ºè¯ç®¡ç†å™¨ç±»ã€‚

**åˆå§‹åŒ–ï¼š**
```python
from prompt_templates import PromptManager

manager = PromptManager("prompt_config.yaml")
```

**ä¸»è¦æ–¹æ³•ï¼š**

##### `get_template(scenario, template_type)`

è·å–æç¤ºè¯æ¨¡æ¿ã€‚

**å‚æ•°ï¼š**
- `scenario` (str): åœºæ™¯åç§°
- `template_type` (str): æ¨¡æ¿ç±»å‹ ("structure_analysis", "search_analysis", "answer_generation")

**è¿”å›å€¼ï¼š** æç¤ºè¯æ¨¡æ¿å­—ç¬¦ä¸²

##### `format_template(scenario, template_type, **kwargs)`

æ ¼å¼åŒ–æç¤ºè¯æ¨¡æ¿ã€‚

**å‚æ•°ï¼š**
- `scenario` (str): åœºæ™¯åç§°
- `template_type` (str): æ¨¡æ¿ç±»å‹
- `**kwargs`: æ¨¡æ¿å˜é‡

**è¿”å›å€¼ï¼š** æ ¼å¼åŒ–åçš„æç¤ºè¯å­—ç¬¦ä¸²

**ç¤ºä¾‹ï¼š**
```python
from prompt_templates import prompt_manager

template = prompt_manager.format_template(
    "water_engineering",
    "structure_analysis",
    document_sample="æ–‡æ¡£å†…å®¹æ ·æœ¬..."
)
```

## ğŸ”§ é…ç½®å‚è€ƒ

### æ¨¡å‹é…ç½® (`model_configs.yaml`)

```yaml
models:
  model_id:
    name: "æ¨¡å‹æ˜¾ç¤ºåç§°"
    api_key: "APIå¯†é’¥"
    base_url: "APIç«¯ç‚¹"
    enabled: true
    max_tokens: 4000
    timeout: 30

scenarios:
  scenario_name:
    name: "åœºæ™¯æ˜¾ç¤ºåç§°"
    description: "åœºæ™¯æè¿°"

directories:
  ocr_files: "ocr_files"
  index_files: "index_files"
  temp_files: "temp_files"

indexing:
  toc_check_page_num: 10
  max_page_num_each_node: 3
  if_add_node_id: true
  if_add_node_summary: true
  if_add_doc_description: true
  if_add_node_text: true
```

### æç¤ºè¯é…ç½® (`prompt_config.yaml`)

```yaml
scenarios:
  scenario_name:
    name: "åœºæ™¯åç§°"
    description: "åœºæ™¯æè¿°"
    structure_analysis: |
      ç»“æ„åˆ†ææç¤ºè¯æ¨¡æ¿...
    search_analysis: |
      æœç´¢åˆ†ææç¤ºè¯æ¨¡æ¿...
    answer_generation: |
      ç­”æ¡ˆç”Ÿæˆæç¤ºè¯æ¨¡æ¿...
```

## ğŸ“Š æ•°æ®ç»“æ„

### OCRæ•°æ®æ ¼å¼

```python
[
    {
        "page_idx": 1,           # é¡µç 
        "type": "text",          # ç±»å‹: "text" æˆ– "table"
        "text": "æ–‡æœ¬å†…å®¹",      # æ–‡æœ¬å†…å®¹
        "text_level": 1,         # æ–‡æœ¬çº§åˆ«
        "table_body": "<table>...</table>",  # è¡¨æ ¼HTMLï¼ˆä»…tableç±»å‹ï¼‰
        "table_level": 1         # è¡¨æ ¼çº§åˆ«ï¼ˆä»…tableç±»å‹ï¼‰
    }
]
```

### ç´¢å¼•æ•°æ®æ ¼å¼

```python
{
    "doc_name": "æ–‡æ¡£åç§°",
    "total_pages": 208,
    "model_id": "qwen3-32b",
    "model_name": "Qwen3-32B",
    "scenario": "water_engineering",
    "created_at": "2024-12-01T10:00:00",
    "structure": [
        {
            "title": "èŠ‚ç‚¹æ ‡é¢˜",
            "start_page": 1,
            "end_page": 3,
            "summary": "èŠ‚ç‚¹æ‘˜è¦",
            "has_tables": True,
            "table_count": 2,
            "key_metrics": ["åº“å®¹", "è£…æœºå®¹é‡"],
            "content_type": "technical_specs",
            "granularity": "high"
        }
    ]
}
```

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´å·¥ä½œæµç¨‹

```python
from ocr_indexing import generate_ocr_index
from intelligent_ocr_search import search_with_llm
from model_manager import ModelManager

# 1. ç”Ÿæˆç´¢å¼•
index_result = generate_ocr_index("document.json", "qwen3-32b")
if index_result["success"]:
    print(f"ç´¢å¼•ç”ŸæˆæˆåŠŸ: {index_result['output_file']}")
    
    # 2. æ‰§è¡Œæœç´¢
    search_result = search_with_llm(
        index_result["output_file"],
        "æ€»åº“å®¹æ˜¯å¤šå°‘ç«‹æ–¹ç±³",
        "qwen3-32b"
    )
    
    if search_result["success"]:
        print(f"æœç´¢ç»“æœ: {search_result['answer']}")
        print(f"Tokenä½¿ç”¨: {search_result['token_stats']['total_tokens']}")
    else:
        print("æœç´¢å¤±è´¥")
else:
    print("ç´¢å¼•ç”Ÿæˆå¤±è´¥")
```

### æ‰¹é‡å¤„ç†

```python
import os
from ocr_indexing import generate_ocr_index

# æ‰¹é‡å¤„ç†å¤šä¸ªOCRæ–‡ä»¶
ocr_files = [f for f in os.listdir("ocr_files") if f.endswith(".json")]
model_id = "qwen3-32b"

for ocr_file in ocr_files:
    print(f"å¤„ç†æ–‡ä»¶: {ocr_file}")
    result = generate_ocr_index(f"ocr_files/{ocr_file}", model_id)
    if result["success"]:
        print(f"âœ… æˆåŠŸ: {result['output_file']}")
    else:
        print(f"âŒ å¤±è´¥: {ocr_file}")
```

---

*æ›´å¤šè¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒå„æ¨¡å—çš„æºä»£ç æ³¨é‡Š*
